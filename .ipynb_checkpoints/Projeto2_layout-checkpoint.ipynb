{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Henrique Mualem Marti\n",
    "\n",
    "Nome: Victor Vergara Arvoverde Albuquerque Cavalcanti\n",
    "\n",
    "Nome: Edgard Neto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import functools\n",
    "import operator\n",
    "from time import sleep\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: @Maul_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass.json') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'coca'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 1000\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 250\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "# api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "# i = 1\n",
    "# msgs = []\n",
    "# for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "#     msgs.append(msg.full_text.lower())\n",
    "#     i += 1\n",
    "#     if i > n:\n",
    "#         break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "# shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "# if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "#     writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "#     dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "#     dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "#     dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "#     dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "#     writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevância</th>\n",
       "      <th>Simulação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>olha a hora que é e eu tive que comprar uma co...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hoje o almoço é c a ingrid....e de quebra uma ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acho que vi 7 ggatinhos eita pega amo mais que...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7h da manhã e eu estava comendo carne assada c...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mano eu e a layla hoje tomamos uns 6 garrafas ...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevância  Simulação\n",
       "0  olha a hora que é e eu tive que comprar uma co...           1        NaN\n",
       "1  hoje o almoço é c a ingrid....e de quebra uma ...           1        NaN\n",
       "2  acho que vi 7 ggatinhos eita pega amo mais que...           2        NaN\n",
       "3  7h da manhã e eu estava comendo carne assada c...           3        NaN\n",
       "4  mano eu e a layla hoje tomamos uns 6 garrafas ...           2        NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " file_tre = pd.read_excel('coca.xlsx' , sheet_name='Treinamento')\n",
    " file_tes = pd.read_excel('coca.xlsx' , sheet_name='Teste')\n",
    " file_tes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legenda de classificação:\n",
    "0: Muito relevante - os *twetts* que expressam opiniões claras e explícitas sobre a bebida \"Coca-Cola\".\n",
    "\n",
    "1: Relevante - os *twetts* que expressam alguma opinião sobre a bebida \"Coca-Cola\".\n",
    "\n",
    "2: Neutro - os *twetts* que não expressam nenhuma opinião sobre a bebida \"Coca-Cola\".\n",
    "\n",
    "3: Irrelevante - os *twetts* que não estão relacionados a bebida \"Coca-Cola\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpeza\n",
    "\n",
    "def stclear(Column):\n",
    "\n",
    "    Column= Column.replace(' \" ',\" \").replace(\" ' \",\" \").replace(' \"',\" \").replace('\" ',\" \")\\\n",
    "    .replace('\"',\" \")\n",
    "    return Column\n",
    "\n",
    "\n",
    "def cleanup(Column):\n",
    "\n",
    "    Column= Column.replace(\"ç\",\"c\").replace(\"â\",\"a\").replace(\"ã\",\"a\").replace(\"à\",\"a\")\\\n",
    "    .replace(\"ê\",\"e\").replace(\"é\",\"e\").replace(\"ô\",\"o\").replace(\"õ\",\"o\").replace(\"/\",\" \")\\\n",
    "    .replace(\"?\",\" \").replace(\"!\",\" \").replace(\"@\",\" \").replace(\"\\n\",\" \").replace(\";\",\" \")\\\n",
    "    .replace(\",\",\"\").replace(\":\",\" \").replace(\"[\",\" \").replace(\"]\",\" \").replace(\"}\",\" \")\\\n",
    "    .replace(\"{\",\" \").replace(\"\\\\\",\" \").replace(' \" ',\" \").replace(\" ' \",\"\").replace(\" * \",\" \")\\\n",
    "    .replace(\" _ \",\" \").replace(\" - \",\" \").replace(\" . \",\" \").replace(\" rt \",\" \").replace(\"…\",\"\")\\\n",
    "    .replace(\"“\",\"\").replace(\"             \",\" \").replace(\"   \",\"\").replace(\"..\",\" \")\\\n",
    "    .replace(\"...\",\" \").replace(\"....\",\" \").replace(\".....\",\" \").replace(\"     \",\" \")\\\n",
    "    .replace(\"\\ \",\"\").replace(\"*\",\"\").replace(\")\",\"\")  \n",
    "    return Column\n",
    "\n",
    "#for items in file.Treinamento:\n",
    "    #p=cleanup(items)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rtcleaner(text):\n",
    "    n = 0\n",
    "    out = []\n",
    "    while n in range(len(text)):\n",
    "        if text[n] == \"r\":\n",
    "            if text[n+1] ==\"t\":\n",
    "                if text[n+2] ==\" \":\n",
    "                    if text[n+3] ==\"@\":\n",
    "                        x = n\n",
    "                        while text[x] != \":\":\n",
    "                            x = x+1\n",
    "                        n = x\n",
    "                        \n",
    "        if text[n] == \"h\":\n",
    "            if text[n+1] ==\"t\":\n",
    "                if text[n+2] ==\"t\":\n",
    "                    if text[n+3] ==\"p\":\n",
    "                        x = n\n",
    "                        while text[x] != \" \":\n",
    "                            x = x+1\n",
    "                        n = x\n",
    "\n",
    "        if text[n] == \"@\":\n",
    "            x = n\n",
    "            while text[x] != \" \":\n",
    "                if x == len(text)-1:\n",
    "                    break\n",
    "                else:\n",
    "                    x = x+1\n",
    "            n = x\n",
    "\n",
    "        out.append(text[n])\n",
    "        n+=1\n",
    "    out = \"\".join(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji(em):\n",
    "    \n",
    "    separa_emoji = emoji.get_emoji_regexp().split(em)\n",
    "    emoji_separado = [substr.split() for substr in separa_emoji]\n",
    "    emoji_separado = functools.reduce(operator.concat, em_separado)\n",
    "    return emoji_separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_tre.Treinamento = file_tre.Treinamento.apply(lambda x: x.lower())\n",
    "#file_tre.Treinamento = file.Treinamento.apply(lambda x: x.translate(str.maketrans('','',string.punctuation)))\n",
    "file_tre.Treinamento = file_tre.Treinamento.apply(lambda x: x.translate(str.maketrans('','',string.digits)))\n",
    "file_tre['Treinamento']=file_tre['Treinamento'].apply(stclear)\n",
    "file_tes['Teste']=file_tes['Teste'].apply(stclear)\n",
    "file_tes['Teste']=file_tes['Teste'].apply(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@rfinh__ a mesa de natal da ines brasil com  c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @dcechetto: as vezes eu não quero tomar ref...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pai bom e o meu mano, eu cheia de ressaca cheg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@mariajoanaff aconteceu comigo esse ano logo d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>não tomem coca cola de madrugada crianças</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@sabriineab hoje é coca cola</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>to tomando uma coca cedo já no intervalo tramp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@dbk_namshi coca-cola logo cedo, namshi? olha....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eu não sou a pessoa que se alimenta da forma m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>acredite no seu potencial e beba coca cola de ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nada como uma coca-cola as  da manhã de uma se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>comendo um miojo com coca pra ir trabalhar mt ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rt @larissapxp: quem toma coca sem gás é psico...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rt @newbrasillm: jesy contou que teve transtor...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>eu vendo a galera malhando e eu comendo um sal...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>domingo: preciso tomar mais água, me cuidar ma...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rt @mariareginafon: @ludel @barodemau @mariste...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@hugoxvt e uma coca l de garrafa pra bater no ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rt @dcechetto: as vezes eu não quero tomar ref...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pequenas vitórias do dia né, hj tinha coca aq ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Treinamento  Relevância\n",
       "0   @rfinh__ a mesa de natal da ines brasil com  c...           1\n",
       "1   rt @dcechetto: as vezes eu não quero tomar ref...           1\n",
       "2   pai bom e o meu mano, eu cheia de ressaca cheg...           1\n",
       "3   @mariajoanaff aconteceu comigo esse ano logo d...           1\n",
       "4           não tomem coca cola de madrugada crianças           1\n",
       "5                        @sabriineab hoje é coca cola           1\n",
       "6   to tomando uma coca cedo já no intervalo tramp...           0\n",
       "7   @dbk_namshi coca-cola logo cedo, namshi? olha....           1\n",
       "8   eu não sou a pessoa que se alimenta da forma m...           2\n",
       "9   acredite no seu potencial e beba coca cola de ...           1\n",
       "10  nada como uma coca-cola as  da manhã de uma se...           1\n",
       "11  comendo um miojo com coca pra ir trabalhar mt ...           1\n",
       "12  rt @larissapxp: quem toma coca sem gás é psico...           3\n",
       "13  rt @newbrasillm: jesy contou que teve transtor...           2\n",
       "14  eu vendo a galera malhando e eu comendo um sal...           2\n",
       "15  domingo: preciso tomar mais água, me cuidar ma...           2\n",
       "16  rt @mariareginafon: @ludel @barodemau @mariste...           2\n",
       "17  @hugoxvt e uma coca l de garrafa pra bater no ...           2\n",
       "18  rt @dcechetto: as vezes eu não quero tomar ref...           1\n",
       "19  pequenas vitórias do dia né, hj tinha coca aq ...           2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_tre.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Relevância, dtype: category\n",
       "Categories (4, int64): [0, 1, 2, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformando quantitativa em qualitativa\n",
    "file_tre.Relevância = file_tre.Relevância.astype('category')\n",
    "file_tre.Relevância.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.360000\n",
       "2    0.269333\n",
       "3    0.260000\n",
       "0    0.110667\n",
       "Name: Relevância, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contagem_relevancia = file_tre.Relevância.value_counts(True)\n",
    "contagem_relevancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_MR = contagem_relevancia[0]\n",
    "prob_R = contagem_relevancia[1]\n",
    "prob_N = contagem_relevancia[2]\n",
    "prob_IR = contagem_relevancia[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_MR=file_tre.loc[file_tre.Relevância==0,:]\n",
    "file_R=file_tre.loc[file_tre.Relevância==1,:]\n",
    "file_N=file_tre.loc[file_tre.Relevância==2,:]\n",
    "file_IR=file_tre.loc[file_tre.Relevância==3,:]\n",
    "MR_txt= \" \".join(file_MR.Treinamento)\n",
    "R_txt= \" \".join(file_R.Treinamento)\n",
    "N_txt= \" \".join(file_N.Treinamento)\n",
    "IR_txt= \" \".join(file_IR.Treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_txt = rtcleaner(N_txt)\n",
    "MR_txt = rtcleaner(MR_txt)\n",
    "R_txt = rtcleaner(R_txt)\n",
    "IR_txt = rtcleaner(IR_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_txt = cleanup(N_txt)\n",
    "MR_txt = cleanup(MR_txt)\n",
    "R_txt = cleanup(R_txt)\n",
    "IR_txt = cleanup(IR_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_MR = pd.Series(MR_txt.split())\n",
    "serie_R = pd.Series(R_txt.split())\n",
    "serie_N = pd.Series(N_txt.split())\n",
    "serie_IR = pd.Series(IR_txt.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_MR = serie_MR.value_counts()\n",
    "tabela_R = serie_R.value_counts()\n",
    "tabela_N = serie_N.value_counts()\n",
    "tabela_IR = serie_IR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010416666666666666"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relativa_MR = serie_MR.value_counts(True)\n",
    "tabela_relativa_R = serie_R.value_counts(True)\n",
    "tabela_relativa_N = serie_N.value_counts(True)\n",
    "tabela_relativa_IR = serie_IR.value_counts(True)\n",
    "tabela_relativa_IR['nao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_MR = tabela_MR[1]\n",
    "item_R = tabela_R[1]\n",
    "item_N = tabela_N[1]\n",
    "item_IR = tabela_IR[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00036126224156692054, 0.0005755395683453237, 0.0003406049109495205, 0.00026200873362445414]\n"
     ]
    }
   ],
   "source": [
    "def probPalavra(palavra):\n",
    "    if palavra in tabela_MR:\n",
    "        a = tabela_MR[palavra]\n",
    "    else:\n",
    "        a = 0\n",
    "    if palavra in tabela_R:\n",
    "        b = tabela_R[palavra]\n",
    "    else:\n",
    "        b = 0\n",
    "    if palavra in tabela_N:\n",
    "        c = tabela_N[palavra]\n",
    "    else:\n",
    "        c = 0\n",
    "    if palavra in tabela_IR:\n",
    "        d = tabela_IR[palavra]\n",
    "    else:\n",
    "        d = 0\n",
    "    probabilidade_MR = ((a+1)/(len(serie_MR)+item_MR))*prob_MR\n",
    "    probabilidade_R = ((b+1)/(len(serie_R)+item_R))*prob_R\n",
    "    probabilidade_N = ((c+1)/(len(serie_N)+item_N))*prob_N\n",
    "    probabilidade_IR = ((d+1)/(len(serie_IR)+item_IR))*prob_IR\n",
    "    \n",
    "    return [probabilidade_MR,probabilidade_R,probabilidade_N,probabilidade_IR]\n",
    "        \n",
    "print(probPalavra(\"amo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def probFrase(frase):\n",
    "    f = str(frase.lower())\n",
    "    f = cleanup(f)\n",
    "    coef_MR = 1\n",
    "    coef_R = 1\n",
    "    coef_N = 1\n",
    "    coef_IR = 1\n",
    "    \n",
    "    for e in f:\n",
    "        coef_MR *= probPalavra(e)[0]\n",
    "        coef_R *= probPalavra(e)[1]\n",
    "        coef_N *= probPalavra(e)[2]\n",
    "        coef_IR *= probPalavra(e)[3]\n",
    "        \n",
    "    if coef_MR>coef_R and coef_MR>coef_N and coef_MR>coef_IR:\n",
    "        return 0\n",
    "        \n",
    "    elif coef_R>coef_MR and coef_R>coef_N and coef_R>coef_IR:\n",
    "        return 1\n",
    "            \n",
    "    elif coef_N>coef_MR and coef_N>coef_R and coef_N>coef_IR:\n",
    "        return 2\n",
    "    \n",
    "    else:\n",
    "        return 3\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#print(probFrase(\"eu quero uma coca gelada\"))\n",
    "print(probFrase(\"as queimadas da Amazônia são responsabilidades do Brasil\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = []\n",
    "for e in file_tes['Teste']:\n",
    "    sim.append(probFrase(e))\n",
    "file_tes['Simulação'] = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      3\n",
       "3      2\n",
       "4      1\n",
       "5      1\n",
       "6      1\n",
       "7      1\n",
       "8      1\n",
       "9      1\n",
       "10     3\n",
       "11     3\n",
       "12     1\n",
       "13     3\n",
       "14     3\n",
       "15     3\n",
       "16     3\n",
       "17     1\n",
       "18     3\n",
       "19     3\n",
       "20     1\n",
       "21     1\n",
       "22     1\n",
       "23     1\n",
       "24     3\n",
       "25     1\n",
       "26     3\n",
       "27     3\n",
       "28     1\n",
       "29     3\n",
       "      ..\n",
       "220    1\n",
       "221    3\n",
       "222    3\n",
       "223    1\n",
       "224    3\n",
       "225    3\n",
       "226    2\n",
       "227    3\n",
       "228    3\n",
       "229    3\n",
       "230    3\n",
       "231    3\n",
       "232    3\n",
       "233    3\n",
       "234    3\n",
       "235    1\n",
       "236    3\n",
       "237    3\n",
       "238    1\n",
       "239    1\n",
       "240    1\n",
       "241    3\n",
       "242    3\n",
       "243    3\n",
       "244    1\n",
       "245    1\n",
       "246    1\n",
       "247    1\n",
       "248    3\n",
       "249    3\n",
       "Name: Simulação, Length: 250, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_tes['Simulação']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(file_tes['Relevância'])\n",
    "MR = 0\n",
    "MR_errados = 0\n",
    "R = 0\n",
    "R_errados = 0\n",
    "N = 0\n",
    "N_errados = 0\n",
    "IR = 0\n",
    "IR_errados = 0\n",
    "\n",
    "for [e,t] in zip(file_tes['Relevância'], file_tes['Simulação']):\n",
    "    if e == 0:\n",
    "        if t == 0:\n",
    "            MR += 1\n",
    "        else:\n",
    "            MR_errados += 1\n",
    "    if e == 1:\n",
    "        if t == 1:\n",
    "            R += 1\n",
    "        else:\n",
    "            R_errados += 1\n",
    "    if e == 2:\n",
    "        if t == 2:\n",
    "            N += 1\n",
    "        else:\n",
    "            N_errados += 1\n",
    "    if e == 3:\n",
    "        if t == 3:\n",
    "            IR += 1\n",
    "        else:\n",
    "            IR_errados +=1\n",
    "#help(zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acertos\n",
      "----------------------\n",
      "Muito Relevantes:  0\n",
      "Relevantes:  32\n",
      "Neutros:  2\n",
      "Irrelevantes:  41\n",
      "----------------------\n",
      "Erros\n",
      "----------------------\n",
      "Muito Relevantes errados:  43\n",
      "Relevantes errados:  40\n",
      "Neutros errados:  65\n",
      "Irrelevantes errados:  27\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Acertos\")\n",
    "print(\"----------------------\")\n",
    "print(\"Muito Relevantes: \", MR)\n",
    "print(\"Relevantes: \", R)\n",
    "print(\"Neutros: \", N)\n",
    "print(\"Irrelevantes: \", IR)\n",
    "print(\"----------------------\")\n",
    "print(\"Erros\")\n",
    "print(\"----------------------\")\n",
    "print(\"Muito Relevantes errados: \", MR_errados)\n",
    "print(\"Relevantes errados: \", R_errados)\n",
    "print(\"Neutros errados: \", N_errados)\n",
    "print(\"Irrelevantes errados: \", IR_errados)\n",
    "print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de acertos:  30.000000000000004 %\n",
      "Porcentagem de erros:  70.0 %\n"
     ]
    }
   ],
   "source": [
    "porcentual_acertos = (((MR/total)+(R/total)+(N/total)+(IR/total)))*100\n",
    "porcentual_errados = (((MR_errados/total)+(R_errados/total)+(N_errados/total)+(IR_errados/total)))*100\n",
    "print(\"Porcentagem de acertos: \", porcentual_acertos, \"%\")\n",
    "print(\"Porcentagem de erros: \", porcentual_errados, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TweepError",
     "evalue": "Twitter error response: status code = 429",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-3edde8eebb93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mmsgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproduto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"extended\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m# Evitando mensagens repitidas:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmsgs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[1;31m# Reached end of current page, get the next page...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__self__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;31m# Parse the response payload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTweepError\u001b[0m: Twitter error response: status code = 429"
     ]
    }
   ],
   "source": [
    "\n",
    "n = 300\n",
    "while True:\n",
    "\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    #Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "    i = 1\n",
    "    msgs = []\n",
    "    for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "        # Evitando mensagens repitidas:\n",
    "        if msg not in msgs: \n",
    "            msgs.append(msg.full_text.lower())\n",
    "            i += 1\n",
    "        if i > n:\n",
    "            break\n",
    "    df = pd.DataFrame({'Teste': pd.Series(msgs)})\n",
    "    df['Teste'] = file_tes['Teste'].apply(cleanup)\n",
    "    df.dropna(inplace=True)\n",
    "    sim=[]\n",
    "    for e in df['Teste']:\n",
    "        sim.append(probFrase(e))\n",
    "    df['Simulação'] = sim\n",
    "    MR = 0\n",
    "    R = 0\n",
    "    N = 0\n",
    "    IR = 0\n",
    "    for e in file_tes['Relevância']:\n",
    "        if e==0:\n",
    "            MR+=1\n",
    "        if e==1:\n",
    "            R+=1\n",
    "        if e==2:\n",
    "            N+=1\n",
    "        else:\n",
    "            IR+=1\n",
    "    print(\"Muito relevantes: \", round((MR/(MR+R+N+IR)),2))\n",
    "    print(\"Relevantes: \", round((R/(MR+R+N+IR)),2))\n",
    "    print(\"Neutros: \", round((N/(MR+R+N+IR)),2))\n",
    "    print(\"Irrelevantes: \", round((IR/(MR+R+N+IR)),2))\n",
    "    sleep(60*60)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis (*feito*)\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B) (*feito*)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
