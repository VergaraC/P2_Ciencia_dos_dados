{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Henrique Mualem Marti\n",
    "\n",
    "Nome: Victor Vergara Arvoverde Albuquerque Cavalcanti\n",
    "\n",
    "Nome: Edgard Neto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import functools\n",
    "import operator\n",
    "from time import sleep\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: @Maul_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass.json') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'coca'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 1000\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 250\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "# api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "# i = 1\n",
    "# msgs = []\n",
    "# for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "#     msgs.append(msg.full_text.lower())\n",
    "#     i += 1\n",
    "#     if i > n:\n",
    "#         break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "# shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "# if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "#     writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "#     dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "#     dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "#     dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "#     dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "#     writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Twitts Treino\n",
    "file_tre = pd.read_excel('coca.xlsx' , sheet_name='Treinamento')\n",
    "#Twitts Teste\n",
    "file_tes = pd.read_excel('coca.xlsx' , sheet_name='Teste')\n",
    "file_tre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legenda de classificação:\n",
    "0: Muito relevante - os *twetts* que expressam opiniões claras e explícitas sobre a bebida \"Coca-Cola\".\n",
    "\n",
    "1: Relevante - os *twetts* que expressam alguma opinião sobre a bebida \"Coca-Cola\".\n",
    "\n",
    "2: Neutro - os *twetts* que não expressam nenhuma opinião sobre a bebida \"Coca-Cola\".\n",
    "\n",
    "3: Irrelevante - os *twetts* que não estão relacionados a bebida \"Coca-Cola\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpeza\n",
    "\n",
    "def stclear(Column):\n",
    "\n",
    "    Column= Column.replace(' \" ',\" \").replace(\" ' \",\" \").replace(' \"',\" \").replace('\" ',\" \")\\\n",
    "    .replace('\"',\" \")\n",
    "    return Column\n",
    "\n",
    "\n",
    "def cleanup(Column):\n",
    "\n",
    "    Column= Column.replace(\"ç\",\"c\").replace(\"â\",\"a\").replace(\"ã\",\"a\").replace(\"à\",\"a\")\\\n",
    "    .replace(\"ê\",\"e\").replace(\"é\",\"e\").replace(\"ô\",\"o\").replace(\"õ\",\"o\").replace(\"/\",\" \")\\\n",
    "    .replace(\"?\",\" \").replace(\"!\",\" \").replace(\"@\",\" \").replace(\"\\n\",\" \").replace(\";\",\" \")\\\n",
    "    .replace(\",\",\"\").replace(\":\",\" \").replace(\"[\",\" \").replace(\"]\",\" \").replace(\"}\",\" \")\\\n",
    "    .replace(\"{\",\" \").replace(\"\\\\\",\" \").replace(' \" ',\" \").replace(\" ' \",\"\").replace(\" * \",\" \")\\\n",
    "    .replace(\" _ \",\" \").replace(\" - \",\" \").replace(\" . \",\" \").replace(\" rt \",\" \").replace(\"…\",\"\")\\\n",
    "    .replace(\"“\",\"\").replace(\"             \",\" \").replace(\"   \",\"\").replace(\"..\",\" \")\\\n",
    "    .replace(\"...\",\" \").replace(\"....\",\" \").replace(\".....\",\" \").replace(\"     \",\" \")\\\n",
    "    .replace(\"\\ \",\"\").replace(\"*\",\"\").replace(\")\",\"\")  \n",
    "    return Column\n",
    "\n",
    "#for items in file.Treinamento:\n",
    "    #p=cleanup(items)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rtcleaner(text):\n",
    "    n = 0\n",
    "    out = []\n",
    "    while n in range(len(text)):\n",
    "        if text[n] == \"r\":\n",
    "            if text[n+1] ==\"t\":\n",
    "                if text[n+2] ==\" \":\n",
    "                    if text[n+3] ==\"@\":\n",
    "                        x = n\n",
    "                        while text[x] != \":\":\n",
    "                            x = x+1\n",
    "                        n = x\n",
    "                        \n",
    "        if text[n] == \"h\":\n",
    "            if text[n+1] ==\"t\":\n",
    "                if text[n+2] ==\"t\":\n",
    "                    if text[n+3] ==\"p\":\n",
    "                        x = n\n",
    "                        while text[x] != \" \":\n",
    "                            x = x+1\n",
    "                        n = x\n",
    "\n",
    "        if text[n] == \"@\":\n",
    "            x = n\n",
    "            while text[x] != \" \":\n",
    "                if x == len(text)-1:\n",
    "                    break\n",
    "                else:\n",
    "                    x = x+1\n",
    "            n = x\n",
    "\n",
    "        out.append(text[n])\n",
    "        n+=1\n",
    "    out = \"\".join(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separação de emoji do resto do texto\n",
    "#Link do fórum nas referências\n",
    "def emoji(emoj):\n",
    "    \n",
    "    separa_emoji = emoji.get_emoji_regexp().split(emoj)\n",
    "    emoji_separado = [substr.split() for substr in separa_emoji]\n",
    "    emoji_separado = functools.reduce(operator.concat, em_separado)\n",
    "    return emoji_separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_tre.Treinamento = file_tre.Treinamento.apply(lambda x: x.lower())\n",
    "#file_tre.Treinamento = file.Treinamento.apply(lambda x: x.translate(str.maketrans('','',string.punctuation)))\n",
    "file_tre.Treinamento = file_tre.Treinamento.apply(lambda x: x.translate(str.maketrans('','',string.digits)))\n",
    "file_tre['Treinamento']=file_tre['Treinamento'].apply(stclear)\n",
    "\n",
    "file_tes['Teste']=file_tes['Teste'].apply(stclear)\n",
    "file_tes['Teste']=file_tes['Teste'].apply(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_tre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando quantitativa em qualitativa\n",
    "file_tre.Relevância = file_tre.Relevância.astype('category')\n",
    "file_tre.Relevância.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contagem_relevancia = file_tre.Relevância.value_counts(True)\n",
    "contagem_relevancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_MR = contagem_relevancia[0]\n",
    "prob_R = contagem_relevancia[1]\n",
    "prob_N = contagem_relevancia[2]\n",
    "prob_IR = contagem_relevancia[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_MR=file_tre.loc[file_tre.Relevância==0,:]\n",
    "file_R=file_tre.loc[file_tre.Relevância==1,:]\n",
    "file_N=file_tre.loc[file_tre.Relevância==2,:]\n",
    "file_IR=file_tre.loc[file_tre.Relevância==3,:]\n",
    "MR_txt= \" \".join(file_MR.Treinamento)\n",
    "R_txt= \" \".join(file_R.Treinamento)\n",
    "N_txt= \" \".join(file_N.Treinamento)\n",
    "IR_txt= \" \".join(file_IR.Treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_txt = rtcleaner(N_txt)\n",
    "MR_txt = rtcleaner(MR_txt)\n",
    "R_txt = rtcleaner(R_txt)\n",
    "IR_txt = rtcleaner(IR_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_txt = cleanup(N_txt)\n",
    "MR_txt = cleanup(MR_txt)\n",
    "R_txt = cleanup(R_txt)\n",
    "IR_txt = cleanup(IR_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_MR = pd.Series(MR_txt.split())\n",
    "serie_R = pd.Series(R_txt.split())\n",
    "serie_N = pd.Series(N_txt.split())\n",
    "serie_IR = pd.Series(IR_txt.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_MR = serie_MR.value_counts()\n",
    "tabela_R = serie_R.value_counts()\n",
    "tabela_N = serie_N.value_counts()\n",
    "tabela_IR = serie_IR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_relativa_MR = serie_MR.value_counts(True)\n",
    "tabela_relativa_R = serie_R.value_counts(True)\n",
    "tabela_relativa_N = serie_N.value_counts(True)\n",
    "tabela_relativa_IR = serie_IR.value_counts(True)\n",
    "tabela_relativa_IR['nao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_MR = tabela_MR[1]\n",
    "item_R = tabela_R[1]\n",
    "item_N = tabela_N[1]\n",
    "item_IR = tabela_IR[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probPalavra(palavra):\n",
    "    if palavra in tabela_MR:\n",
    "        a = tabela_MR[palavra]\n",
    "    else:\n",
    "        a = 0\n",
    "    if palavra in tabela_R:\n",
    "        b = tabela_R[palavra]\n",
    "    else:\n",
    "        b = 0\n",
    "    if palavra in tabela_N:\n",
    "        c = tabela_N[palavra]\n",
    "    else:\n",
    "        c = 0\n",
    "    if palavra in tabela_IR:\n",
    "        d = tabela_IR[palavra]\n",
    "    else:\n",
    "        d = 0\n",
    "    probabilidade_MR = ((a+1)/(len(serie_MR)+item_MR))*prob_MR\n",
    "    probabilidade_R = ((b+1)/(len(serie_R)+item_R))*prob_R\n",
    "    probabilidade_N = ((c+1)/(len(serie_N)+item_N))*prob_N\n",
    "    probabilidade_IR = ((d+1)/(len(serie_IR)+item_IR))*prob_IR\n",
    "    \n",
    "    return [probabilidade_MR,probabilidade_R,probabilidade_N,probabilidade_IR]\n",
    "        \n",
    "print(probPalavra(\"amo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probFrase(frase):\n",
    "    f = str(frase.lower())\n",
    "    f = cleanup(f)\n",
    "    coef_MR = 1\n",
    "    coef_R = 1\n",
    "    coef_N = 1\n",
    "    coef_IR = 1\n",
    "    \n",
    "    for e in f:\n",
    "        coef_MR *= probPalavra(e)[0]\n",
    "        coef_R *= probPalavra(e)[1]\n",
    "        coef_N *= probPalavra(e)[2]\n",
    "        coef_IR *= probPalavra(e)[3]\n",
    "        \n",
    "    if coef_MR>coef_R and coef_MR>coef_N and coef_MR>coef_IR:\n",
    "        return 0\n",
    "        \n",
    "    elif coef_R>coef_MR and coef_R>coef_N and coef_R>coef_IR:\n",
    "        return 1\n",
    "            \n",
    "    elif coef_N>coef_MR and coef_N>coef_R and coef_N>coef_IR:\n",
    "        return 2\n",
    "    \n",
    "    else:\n",
    "        return 3\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#print(probFrase(\"eu quero uma coca gelada\"))\n",
    "print(probFrase(\"as queimadas da Amazônia são responsabilidades do Brasil\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = []\n",
    "for e in file_tes['Teste']:\n",
    "    sim.append(probFrase(e))\n",
    "file_tes['Simulação'] = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_tes['Simulação']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(file_tes['Relevância'])\n",
    "MR_certos = 0\n",
    "MR_errados = 0\n",
    "R_certos = 0\n",
    "R_errados = 0\n",
    "N_certos = 0\n",
    "N_errados = 0\n",
    "IR_certos = 0\n",
    "IR_errados = 0\n",
    "\n",
    "for [e,t] in zip(file_tes['Relevância'], file_tes['Simulação']):\n",
    "    if e == 0:\n",
    "        if t == 0:\n",
    "            MR_certos += 1\n",
    "        else:\n",
    "            MR_errados += 1\n",
    "    if e == 1:\n",
    "        if t == 1:\n",
    "            R_certos += 1\n",
    "        else:\n",
    "            R_errados += 1\n",
    "    if e == 2:\n",
    "        if t == 2:\n",
    "            N_certos += 1\n",
    "        else:\n",
    "            N_errados += 1\n",
    "    if e == 3:\n",
    "        if t == 3:\n",
    "            IR_certos += 1\n",
    "        else:\n",
    "            IR_errados +=1\n",
    "#help(zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Acertos\")\n",
    "print(\"----------------------\")\n",
    "print(\"Muito Relevantes: \", MR_certos)\n",
    "print(\"Relevantes: \", R_certos)\n",
    "print(\"Neutros: \", N_certos)\n",
    "print(\"Irrelevantes: \", IR_certos)\n",
    "print(\"----------------------\")\n",
    "print(\"Erros\")\n",
    "print(\"----------------------\")\n",
    "print(\"Muito Relevantes errados: \", MR_errados)\n",
    "print(\"Relevantes errados: \", R_errados)\n",
    "print(\"Neutros errados: \", N_errados)\n",
    "print(\"Irrelevantes errados: \", IR_errados)\n",
    "print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentual_acertos = (((MR_certos/total)+(R_certos/total)+(N_certos/total)+(IR_certos/total)))*100\n",
    "porcentual_errados = (((MR_errados/total)+(R_errados/total)+(N_errados/total)+(IR_errados/total)))*100\n",
    "print(\"Porcentagem de acertos: \", porcentual_acertos, \"%\")\n",
    "print(\"Porcentagem de erros: \", porcentual_errados, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 300\n",
    "while True:\n",
    "    break\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    #Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "    i = 1\n",
    "    msgs = []\n",
    "    for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "        # Evitando mensagens repitidas:\n",
    "        if msg not in msgs: \n",
    "            msgs.append(msg.full_text.lower())\n",
    "            i += 1\n",
    "        if i > n:\n",
    "            break\n",
    "    df = pd.DataFrame({'Teste': pd.Series(msgs)})\n",
    "    df['Teste'] = file_tes['Teste'].apply(cleanup)\n",
    "    df.dropna(inplace=True)\n",
    "    sim=[]\n",
    "    for e in df['Teste']:\n",
    "        sim.append(probFrase(e))\n",
    "    df['Simulação'] = sim\n",
    "    MR = 0\n",
    "    R = 0\n",
    "    N = 0\n",
    "    IR = 0\n",
    "    for e in file_tes['Relevância']:\n",
    "        if e==0:\n",
    "            MR+=1\n",
    "        if e==1:\n",
    "            R+=1\n",
    "        if e==2:\n",
    "            N+=1\n",
    "        else:\n",
    "            IR+=1\n",
    "    print(\"Muito relevantes: \", round((MR/(MR+R+N+IR)),2))\n",
    "    print(\"Relevantes: \", round((R/(MR+R+N+IR)),2))\n",
    "    print(\"Neutros: \", round((N/(MR+R+N+IR)),2))\n",
    "    print(\"Irrelevantes: \", round((IR/(MR+R+N+IR)),2))\n",
    "    sleep(60*60)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a análise é possível concluir que o classificador criado não é eficaz para a classificação, pois apresenta apenas 30% de acerto, assim não deveria ser utilizado para a classificação de twitts em níveis de relevância para o setor de marketing da \"Coca-Cola\". Caso fossem utilizados mais twitts para o treinamento, provavelmete o índice de acerto seria maior, pois assim teria um aumento na quantidade de palavras do sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis (*feito*)\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B) (*feito com 4 categorias*)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "[How to split emoji from each other python?](https://stackoverflow.com/questions/49921720/how-to-split-emoji-from-each-other-python) **Função utilizada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
